<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>DxD Lab | publications</title>
    <meta name="author" content="  " />
    <meta name="description" content="KAIST DxD Lab
" />


    <!-- Bootstrap & MDB -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="apple-touch-icon" sizes="180x180" href="assets/img/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="assets/img/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="assets/img/favicon/favicon-16x16.png">
    <link rel="manifest" href="/assets/img/favicon/site.webmanifest">
    <link rel="mask-icon" href="assets/img/favicon/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://dxd-lab.github.io/publications/">

    <!-- Dark Mode -->
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
  </head>

  <!-- Body -->
  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://dxd-lab.github.io/">DxD Lab</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>
              -->

              <!-- Other pages -->
              <li class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">people</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/members/">members</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/alumni/">alumni</a>
                </div>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/contact/">contact</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="category">Data</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"><img class="preview rounded" src="/assets/img/publication_preview/k.png"></div>

        <!-- Entry bib key -->
        <div id="kk" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Korean Emoticons: Understanding How Subtle Emotional Differences Are Evoked Online</div>
          <!-- Author -->
          <div class="author">Kang, Chowon, Hong, Jong-ok, Chang, Wooje, Suk, Hyeon-jeong, and Hong, Hwajung
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CSCW ’22,</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Online conversations through text have limitations in expressing emotions that could cause miscommunications across cultures. In this work, we study the Korean emotional expressions in text focusing on how people perceive emotional intentions through the use of emotion-expressing Korean characters. We define them as Korean Emoticons (‘ㅋ’, ‘ㅎ’, ‘ㅠ’), onomatopoeic characters often used to express emotions for text-based communication. We examine the participants’ understanding and usage of Korean Emoticons by conducting an online survey asking to evaluate emotional contents of given sentences and interviews to explain personal experiences. We found that the different numbers of Korean emoticons used evoke different emotions, and that negative emoticons amplify positive emotions in positive contexts and positive emoticons alleviate negative emotions in negative contexts, while emoticons in neutral contexts have varying impacts depending on the context. We further discuss design implications on how text suggestion tools can support users taking emotional intentions into account.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="GeniAuti" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">GeniAuti: Toward Data-Driven Interventions to Challenging Behaviors of Autistic Children through Caregivers’ Tracking</div>
          <!-- Author -->
          <div class="author">Jo, Eunkyung, park, Seora, Bang, Hyeonseok, Hong, Youngeun, Kim, Yeni, Choi, Jungwon, Kim, Bung Nyun, Epstein, Daniel A., and Hong, Hwajung
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CSCW ’22,</em> Apr 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/abs/10.1145/3512939" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Challenging behaviors significantly impact learning and socialization of autistic children and can stress and burden their caregivers. Documentation of challenging behaviors is fundamental for identifying what environmental factors influence them, such as how others respond to a child’s such behaviors. Caregiver-tracked data on their child’s challenging behaviors can help clinical experts make informed recommendations about how to manage such behaviors. To support caregivers in recording their children’s challenging behaviors, we developed GeniAuti, a mobile-based data-collection tool built upon a clinical data collection form to document challenging behaviors and other clinically relevant contextual information such as place, duration, intensity, and what triggers such behaviors. Through an open-ended deployment with 19 parent-child pairs and three expert collaborators, caregivers found GeniAuti valuable for (1) becoming more attentive and reflective to behavioral contexts, including their own response strategies, (2) discovering positive aspects of their children’s behaviors, and (3) promoting collaboration with clinical experts around the caregiver-tracked data to develop tailored intervention strategies for their children. However, participant experiences surface challenges of logging behaviors in social circumstances, conflicting views between caregivers and clinical experts around the structured recording process, and emotional struggles resulting from recording and reflecting on intensely negative experiences. Considering the complex nature of caregiver-based health tracking and caregiver–clinician collaboration, we suggest design opportunities for facilitating negotiations between caregivers and clinicians and accounting for caregivers’ emotional needs.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="stickgoals" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Sticky Goals: Understanding Goal Commitments for Behavioral Changes in the Wild</div>
          <!-- Author -->
          <div class="author">Lee, Hyunsoo, Kim, Auk, Hong, Hwajung, and Lee, Uichin
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CHI ’21,</em> May 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3411764.3445295" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Sticky%20Goals%20Understanding%20Goal%20Commitments%20for%20Behavioral%20Changes%20in%20the%20Wild.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>A commitment device, an attempt to bind oneself for a successful goal achievement, has been used as an effective strategy to promote behavior change. However, little is known about how commitment devices are used in the wild, and what aspects of commitment devices are related to goal achievements. In this paper, we explore a large-scale dataset from stickK, an online behavior change support system that provides both financial and social commitments. We characterize the patterns of behavior change goals (e.g., topics and commitment setting) and then perform a series of multilevel regression analyses on goal achievements. Our results reveal that successful goal achievements are largely dependent on the configuration of financial and social commitment devices, and a mixed commitment setting is considered beneficial. We discuss how our findings could inform the design of effective commitment devices, and how large-scale data can be leveraged to support data-driven goal elicitation and customization.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="adio" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">ADIO: An Interactive Artifact Physically Representing the Intangible Digital Audiobook Listening Experience in Everyday Living Spaces</div>
          <!-- Author -->
          <div class="author">Lee, Kyung-Ryong, Kim, Beom, Kim, Junyoung, Hong, Hwajung, and Park, Young-Woo
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CHI ’21,</em> May 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3411764.3445440" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/ADIO%20An%20Interactive%20Artifact%20Physically%20Representing%20the%20Intangible%20Digital%20Audiobook%20Listening%20Experience%20in%20Everyday%20Living%20Spaces.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Although audiobooks are increasingly being used, people tend to perceive audiobook experiences as ’not real reading’ due to its intangibility and ephemerality. In this paper, we developed ADIO, a device augmenting audiobook experience through representing personal listening state in the form of an interactive physical bookshelf. ADIO displays a user’s listening progress through a pendant’s changing length and the user’s digital audiobook archive titles. The result of our four-week in-field study with six participants revealed that ADIO provided proof of the user’s listening-to, which brought a sense of reading and gave a trigger for recalling the listened-to audiobook content. Additionally, audiobooks’ improved visibility reminded participants to listen to them, and ADIO’s physical interaction allowed participants to form personal patterns for listening to audiobooks. Our findings proposed new methods for augmenting the audiobook listening experience at three stages and further implications for designing physical curation on users’ digital archives.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="self-tracker" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Understanding Parenting Stress through Co-designed Self-Trackers</div>
          <!-- Author -->
          <div class="author">Jo, Eunkyung, Toombs, Austin L., Gray, Colin M., and Hong, Hwajung
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CHI ’20,</em> Apr 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3313831.3376359" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Understanding%20Parenting%20Stress%20through%20Co-designed%20Self-Trackers.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>New parents often experience significant stress as they take on new roles and responsibilities. Stress management and mental wellbeing are two areas in which personal informatics (PI) research has gained attention, and there is an opportunity to investigate how parenting stress can be mitigated through PI practices. In this paper, we present the results of a co-designed technology probe study through which we deployed individualized self-trackers with new parents. We investigate the stress management topics new parents are interested in tracking and how — and with what goals—they engage in self-directed PI practices. Our findings indicate that PI practices can potentially enable parents to: re-discover positive aspects of their everyday lives; identify better-suited stress management strategies; and facilitate spousal communication about shared responsibilities. We discuss how self-tracking experiences for the mental wellness of parents can be better designed.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="stressManagement" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Toward Future-Centric Personal Informatics: Expecting Stressful Events and Preparing Personalized Interventions in Stress Management</div>
          <!-- Author -->
          <div class="author">Lee, Kwangyoung, Cho, Hyewon, Toshnazarov, Kobiljon, Narziev, Nematjon, Rhim, So Young, Han, Kyungsik, Noh, YoungTae, and Hong, Hwajung
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CHI ’20,</em> Apr 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3313831.3376475" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Toward%20Future-Centric%20Personal%20Informatics%20Expecting%20Stressful%20Events%20and%20Preparing%20Personalized%20Interventions%20in%20Stress%20Management" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Stress is caused by a variety of events in our daily lives. By anticipating stressful situations, we can prepare and better cope with stressors when they actually occur. However, many past-centric personal informatics (PI) tools focus on capturing events that already happened and analyzing the data. In this work, we examine how anticipation — a future-centric self-tracking practice — could be used to manage daily stress levels. To address this, we built MindForecaster, a calendar- mediated stress anticipation application that allows users to expect stressful events in advance, generates activities to mitigate stress, and evaluates actual stress levels compared to previously estimated stress levels. In a 30-day deployment with 47 users, the users who explicitly planned and executed coping interventions reported reduced stress more than those who only expected stressful events. We suggest design implications for stress management by incorporating the properties of anticipation into current PI models.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="mindnavigator" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">MindNavigator: Exploring the stress and self-interventions for mental wellness</div>
          <!-- Author -->
          <div class="author">Lee, Kwangyoung, and Hong, Hwajung
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CHI ’18,</em> Apr 2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3173574.3174146" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/MindNavigator%20Exploring%20the%20Stress%20and%20Self-Interventions%20for%20Mental%20Wellness.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Mental wellness is a desirable health outcome for students. However, current personal informatics systems do not adequately support students in creating concrete mental health-related goals and turning them into actionable plans. In this paper, we introduce MindNavigator - a workshop in which groups of college students were invited to generate behavioral change goals to manage daily life stress and practice personalized interventions for two weeks. We describe the manner in which participants identified both stressors and pleasures to create actionable, engaging, and open-ended behavioral plans that aided in stress relief. We found that the social nature of the workshop helped participants understand themselves and execute self-intervention in new ways. Through this practice, we build on prior studies to propose an analytical framework of personal informatics for mental wellness.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="Tangible" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Designing for Self-Tracking of Emotion and Experience with Tangible Modality</div>
          <!-- Author -->
          <div class="author">Lee, Kwangyoung, and Hong, Hwajung
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CHI ’17,</em> Jun 2017
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3064663.3064697" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Designing%20for%20Self-Tracking%20of%20Emotion%20and%20Experience%20with%20Tangible%20Modality.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Self-tracking technologies have been developed to understand the self. Emotions are critical to understanding one’s daily life; however, tracking the emotion is challenging due to the implicit form of data. In this paper, we introduce MindTracker, an approach for tracking emotion through a tangible interaction with plasticine clay. We explored the benefits and challenges of MindTracker via a two-week data collection study with 16 college students as well as via interviews with three clinical mental health experts. MindTracker is designed for users to craft a form that represents emotion using clay and to describe the experience that evokes the emotion using a diary. We found that the tangible modality of MindTracker motivated the participants to express various aspects of emotions. In addition, MindTracker’s data collection and reflection process could have therapeutic properties, such as expressive therapy, self-soothing, and emotional self-regulation. We conclude this paper by discussing the design features of emotion-tracking tools and opportunities to use MindTracker to promote mental health.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="category">AI / Algorithm</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="lim" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Exploring the Use of a Voice-based Conversational Agent to Empower Adolescents with Autism Spectrum Disorder</div>
          <!-- Author -->
          <div class="author">Cha, Inha, Kim, Sung-In, Hong, Hwajung, Yoo, Heejeong, and Lim, Youn-kyung
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CHI ’21,</em> May 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3411764.3445116" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Exploring%20the%20Use%20of%20a%20Voice-based%20Conversational%20Agent%20to%20Empower%20Adolescents%20with%20Autism%20Spectrum%20Disorder.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Voice-based Conversational Agents (VCA) have served as personal assistants that support individuals with special needs. Adolescents with Autism Spectrum Disorder (ASD) may also benefit from VCAs to deal with their everyday needs and challenges, ranging from self-care to social communications. In this study, we explored how VCAs could encourage adolescents with ASD in navigating various aspects of their daily lives through the two-week use of VCAs and a series of participatory design workshops. Our findings demonstrated that VCAs could be an engaging, empowering, emancipating tool that supports adolescents with ASD to address their needs, personalities, and expectations, such as promoting self-care skills, regulating negative emotions, and practicing conversational skills. We propose implications of using off-the-shelf technologies as a personal assistant to ASD users in Assistive Technology design. We suggest design implications for promoting positive opportunities while mitigating the remaining challenges of VCAs for adolescents with ASD.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="How Do You Feel Online" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">How Do You Feel Online: Exploiting Smartphone Sensors to Detect Transitory Emotions during Social Media Use</div>
          <!-- Author -->
          <div class="author">Ruensuk, Mintra, Cheon, Eunyong, Hong, Hwajung, and Oakley, Ian
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IMWUT ’20,</em> Dec 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3432223" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/How%20Do%20You%20Feel%20Online%20Exploiting%20Smartphone%20Sensors%20to%20Detect%20Transitory%20Emotions%20during%20Social%20Media%20Use.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Emotions are an intrinsic part of the social media user experience that can evoke negative behaviors such as cyberbullying and trolling. Detecting the emotions of social media users may enable responding to and mitigating these problems. Prior work suggests this may be achievable on smartphones: emotions can be detected via built-in sensors during prolonged input tasks. We extend these ideas to a social media context featuring sparse input interleaved with more passive browsing and media consumption activities. To achieve this, we present two studies. In the first, we elicit participant’s emotions using images and videos and capture sensor data from a mobile device, including data from a novel passive sensor: its built-in eye-tracker. Using this data, we construct machine learning models that predict self-reported binary affect, achieving 93.20% peak accuracy. A follow-up study extends these results to a more ecologically valid scenario in which participants browse their social media feeds. The study yields high accuracies for both self-reported binary valence (94.16%) and arousal (92.28%). We present a discussion of the sensors, features and study design choices that contribute to this high performance and that future designers and researchers can use to create effective and accurate smartphone-based affect detection systems.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="category">Inclusion / Health</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"><img class="preview rounded" src="/assets/img/publication_preview/mindscope.png"></div>

        <!-- Entry bib key -->
        <div id="mindScope" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Prediction for Retrospection: Integrating Algorithmic Stress Prediction into Personal Informatics Systems for College Students’ Mental Health</div>
          <!-- Author -->
          <div class="author">Kim, Taewan, Kim, Haesoo, Lee, Ha Yeon, Goh, Hwarang, Abdigapporov, Shakhboz, Jeong, Mingon, Cho, Hyunsung, Han, Kyungsik, Noh, Youngtae, Lee, Sung-Ju, and Hong, Hwajung
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CHI ’22,</em> Apr 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3491102.3517701" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Reflecting on stress-related data is critical in addressing one’s mental health. Personal Informatics (PI) systems augmented by algorithms and sensors have become popular ways to help users collect and reflect on data about stress. While prediction algorithms in the PI systems are mainly for diagnostic purposes, few studies examine how the explainability of algorithmic prediction can support user-driven self-insight. To this end, we developed MindScope, an algorithm-assisted stress management system that determines user stress levels and explains how the stress level was computed based on the user’s everyday activities captured by a smartphone. In a 25-day field study conducted with 36 college students, the prediction and explanation supported self-reflection, a process to re-establish preconceptions about stress by identifying stress patterns and recalling past stress levels and patterns that led to coping planning. We discuss the implications of exploiting prediction algorithms that facilitate user-driven retrospection in PI systems.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"><img class="preview rounded" src="/assets/img/publication_preview/youtube.png"></div>

        <!-- Entry bib key -->
        <div id="inclusiveAlgorithm" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">“It’s not wrong, but I’m quite disappointed”: Toward an Inclusive Algorithmic Experience for Content Creators with Disabilities</div>
          <!-- Author -->
          <div class="author">Choi, Dasom, Lee, Uichin, and Hong, Hwajung
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CHI ’22</em> Apr 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3491102.3517574" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/%E2%80%9CIt%E2%80%99s%20not%20wrong,%20but%20I%E2%80%99m%20quite%20disappointed%E2%80%9D%20-%20Toward%20an%20Inclusive%20Algorithmic%20Experience%20for%20Content%20Creators%20with%20Disabilities.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>YouTube is a space where people with disabilities can reach a wider online audience to present what it is like to have disabilities. Thus, it is imperative to understand how content creators with disabilities strategically interact with algorithms to draw viewers around the world. However, considering that the algorithm carries the risk of making less inclusive decisions for users with disabilities, whether the current algorithmic experiences (AXs) on video platforms is inclusive for creators with disabilities is an open question. To address that, we conducted semi-structured interviews with eight YouTubers with disabilities. We found that they aimed to inform the public of diverse representations of disabilities, which led them to work with algorithms by strategically portraying disability identities. However, they were disappointed that the way the algorithms work did not sufficiently support their goals. Based on findings, we suggest implications for designing inclusive AXs that could embrace creators’ subtle needs.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"><img class="preview rounded" src="/assets/img/publication_preview/4.jpg"></div>

        <!-- Entry bib key -->
        <div id="Instagram" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Sad or just jealous? Using Experience Sampling to Understand and Detect Negative Affective Experiences on Instagram</div>
          <!-- Author -->
          <div class="author">Ruensuk, Mintra, Kim, Taewan, Hong, Hwajung, and Oakley, Ian
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CHI ’22</em> Apr 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/abs/10.1145/3491102.3517561" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Social Network Services (SNSs) evoke diverse affective experiences. While most are positive, many authors have documented both the negative emotions that can result from browsing SNS and their impact: Facebook depression is a common term for the more severe results. However, while the importance of the emotions experienced on SNSs is clear, methods to catalog them, and systems to detect them, are less well developed. Accordingly, this paper reports on two studies using a novel contextually triggered Experience Sampling Method to log surveys immediately after using Instagram, a popular image-based SNS, thus minimizing recall biases. The first study improves our understanding of the emotions experienced while using SNSs. It suggests that common negative experiences relate to appearance comparison and envy. The second study captures smartphone sensor data during Instagram sessions to detect these two emotions, ultimately achieving peak accuracies of 95.78% (binary appearance comparison) and 93.95% (binary envy).</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="taewan2021JMIR" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Understanding University Students’ Experiences, Perceptions, and Attitudes Toward Peers Displaying Mental Health–Related Problems on Social Networking Sites: Online Survey and Interview Study</div>
          <!-- Author -->
          <div class="author">Kim, Taewan, and Hong, Hwajung
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>JMIR Mental Health ’21,</em> Apr 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://mental.jmir.org/2021/10/e23465" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Understanding%20University%20Students%E2%80%99%20Experiences,%20Perceptions,%20and%20Attitudes%20Toward%20Peers%20Displaying%20Mental%20Health%E2%80%93Related%20Problems%20on%20Social%20Networking%20Sites%20Online%20Survey%20and%20Interview%20Study.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="contactracing" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Comparing Perspectives Around Human and Technology Support for Contact Tracing</div>
          <!-- Author -->
          <div class="author">Lu, Xi, Reynolds, Tera L., Jo, Eunkyung, Hong, Hwajung, Page, Xinru, Chen, Yunan, and Epstein, Daniel A.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CHI ’21,</em> May 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3411764.3445669" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Comparing%20Perspectives%20Around%20Human%20and%20Technology%20Support%20for%20Contact%20Tracing.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Various contact tracing approaches have been applied to help contain the spread of COVID-19, with technology-based tracing and human tracing among the most widely adopted. However, governments and communities worldwide vary in their adoption of digital contact tracing, with many instead choosing the human approach. We investigate how people perceive the respective benefits and risks of human and digital contact tracing through a mixed-methods survey with 291 respondents from the United States. Participants perceived digital contact tracing as more beneficial for protecting privacy, providing convenience, and ensuring data accuracy, and felt that human contact tracing could help provide security, emotional reassurance, advice, and accessibility. We explore the role of self-tracking technologies in public health crisis situations, highlighting how designs must adapt to promote societal benefit rather than just self-understanding. We discuss how future digital contact tracing can better balance the benefits of human tracers and technology amidst the complex contact tracing process and context.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="socialTranslucence" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Enriched Social Translucence in Medical Crowdfunding</div>
          <!-- Author -->
          <div class="author">Kim, Jennifer G., Kong, Ha-Kyung, Hong, Hwajung, and Karahalios, Karrie
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>DIS ’20,</em> Jul 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3357236.3395520" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Enriched%20Social%20Translucence%20in%20Medical%20Crowdfunding.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Social translucence theory argues that online collaboration systems should make contributors’ activities visible to better achieve a common goal. Currently in medical crowdfunding sites, various non-monetary contributions integral to the success of a campaign, such as campaign promotions and offline support, are less visible than monetary contributions. Our work investigates ways to enrich social translucence in medical crowdfunding by aggregating and visualizing non-monetary contributions that reside outside of the current crowdfunding space. Three different styles of interactive visualizations were built and evaluated with medical crowdfunding beneficiaries and contributors. Our results reveal the perceived benefits and challenges of making the previously invisible non-monetary contributions visible using various design features in the visualizations. We discuss our findings based on the social translucence framework–visibility, awareness, and accountability–and suggest design guidelines for crowdfunding platform designers.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="mamas" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">MAMAS: Supporting Parent–Child Mealtime Interactions Using Automated Tracking and Speech Recognition</div>
          <!-- Author -->
          <div class="author">Jo, Eunkyung, Bang, Hyeonseok, Ryu, Myeonghan, Sung, Eun Jee, Leem, Sungmook, and Hwajung Hong, 
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CSCW ’20,</em> May 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3392876" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/MAMAS%20Supporting%20Parent%E2%80%93Child%20Mealtime%20Interactions%20Using%20Automated%20Tracking%20and%20Speech%20Recognition.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Many parents of young children find it challenging to deal with their children’s eating problems, and parent–child mealtime interaction is fundamental in forming children’s healthy eating habits. In this paper, we present the results of a three-week study through which we deployed a mealtime assistant application, MAMAS, for monitoring parent–child mealtime conversation and food intake with 15 parent–child pairs. Our findings indicate that the use of MAMAS helped 1) increase children’s autonomy during mealtime, 2) enhance parents’ self-awareness of their words and behaviors, 3) promote the parent–child relationship, and 4) positively influence the mealtime experiences of the entire family. The study also revealed some challenges in eating behavior interventions due to the complex dynamics of childhood eating problems. Based on the findings, we discuss how a mealtime assistant application can be better designed for parents and children with challenging eating behaviors.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="youHelpYourself" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">In Helping a Vulnerable Bot, You Help Yourself: Designing a Social Bot as a Care-Receiver to Promote Mental Health and Reduce Stigma</div>
          <!-- Author -->
          <div class="author">Kim, Taewan, Ruensuk, Mintra, and Hong, Hwajung
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>CHI ’20,</em> Apr 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3313831.3376743" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/In%20Helping%20a%20Vulnerable%20Bot,%20You%20Help%20Yourself%20Designing%20a%20Social%20Bot%20as%20a%20Care-Receiver%20to%20Promote%20Mental%20Health%20and%20Reduce%20Stigma.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Helping others can have a positive effect on both the giver and the receiver. However, supporting someone with depression can be complicated and overwhelming. To address this, we proposed a Facebook-based social bot displaying depressive symptoms and disclosing vulnerable experiences that allows users to practice providing reactions online. We investigated how 55 college students interacted with the social bot for three weeks and how these support-giving experiences affected their mental health and stigma. By responding to the bot, the participants reframed their own negative experiences, reported reduced feelings of danger regarding an individual with depression and increased willingness to help the person, and presented favorable attitudes toward seeking treatment for depression. We discuss design opportunities for accessible social bots that could help users to keep practicing peer support interventions without fear of negative consequences.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"></div>

        <!-- Entry bib key -->
        <div id="aBetterSelf" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Toward becoming a better self: Understanding self-tracking experiences of adolescents with autism spectrum disorder using custom trackers</div>
          <!-- Author -->
          <div class="author">Kim, Sung-In, Jo, Eunkyung, Ryu, Myeonghan, Cha, Inha, Kim, Young-Ho, Yoo, Heejung, and Hong, Hwajung
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>PervasiveHealth ’19,</em> May 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3329189.3329209" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Toward%20becoming%20a%20better%20self%20Understanding%20self-tracking%20experiences%20of%20adolescents%20with%20autism%20spectrum%20disorder%20using%20custom%20trackers.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Adolescence is a challenging period, particularly for individuals with autism spectrum disorder (ASD), due to having little knowledge about themselves. Self-management is a strategy to enhance self-understanding through continuous self-monitoring, which can support adaptive transitions to adulthood. Meanwhile, the advent of digital self-tracking tools enables users to collect and reflect on data about themselves. In this work, we investigated how adolescents with ASD kept track of their everyday lives to better understand themselves using a custom self-tracking platform, OmniTrack, over a two-week period. Our findings indicate that personalized self-tracking experiences enable adolescents to monitor the detailed contexts, causes, and consequences of problematic situations; regulate negative emotion and anxiety while interacting with the tracker; and communicate through data with their caregivers, teachers, and therapists. Building on these findings, we suggest the design of a new form of flexible, scaffolded self-tracking technique that can inform both researchers for designing pervasive health technologies for adolescents with ASD and clinicians for guiding adolescents with ASD toward better self-management using such technologies.</p>
          </div>
        </div>
      </div>
</li>
</ol>


</div>

          </article>

        </div>

    </div>
    
  </body>

  <!-- jQuery -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  <!-- Mansory & imagesLoaded -->
  <script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
  <script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/mansory.js" type="text/javascript"></script>
  
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  
</html>

